{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3IMqtPR9adb",
        "outputId": "11a96c66-d84b-41d4-d568-73a9f43f351a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsuFreiS-Som",
        "outputId": "aceaa313-d7f5-4901-cfbd-9cecd49148b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.10/dist-packages (1.81)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQz1Ve_l-ZdD",
        "outputId": "49bc7602-dbb9-48af-d57f-baef0794fb4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg6HzDct3OXt",
        "outputId": "c5497009-5a5a-4aef-f198-fcdcd7c7bca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nlpaug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXVl5PGW3REH",
        "outputId": "33999852-979e-425c-a78b-4a0fbfc3c179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nlpaug in /usr/local/lib/python3.10/dist-packages (1.1.11)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.31.0)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.11.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2023.11.17)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5VIXiYW9U0O"
      },
      "outputs": [],
      "source": [
        "from Bio import Entrez\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import random\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HKi3fHA9U0S"
      },
      "source": [
        "## **Collection Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN8VpO7c9U0T"
      },
      "source": [
        "# Step 1: Reading and Storing Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmlpWTPf9U0U"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/BIO/pubmed_ids.csv')\n",
        "pubmed_ids = df['PubMed ID'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNP6ogF79U0U"
      },
      "outputs": [],
      "source": [
        "# Set your email address for identification\n",
        "Entrez.email = \"sidesh.sundar@example.com\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6B06tod9U0V"
      },
      "outputs": [],
      "source": [
        "# Function to fetch abstract\n",
        "def fetch_abstract(pubmed_id):\n",
        "    try:\n",
        "        handle = Entrez.efetch(db=\"pubmed\", id=str(pubmed_id), retmode=\"xml\")\n",
        "        record = Entrez.read(handle)\n",
        "        abstract = record['PubmedArticle'][0]['MedlineCitation']['Article']['Abstract']['AbstractText'][0]\n",
        "        return abstract\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching abstract for PubMed ID {pubmed_id}: {str(e)}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRkxQC1V9U0V"
      },
      "outputs": [],
      "source": [
        "# Fetch abstracts for all PubMed IDs\n",
        "pubmed_abstracts = [fetch_abstract(pubmed_id) for pubmed_id in pubmed_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ORTRPtp9U0W"
      },
      "outputs": [],
      "source": [
        "# Filter out None values (failed to fetch abstracts)\n",
        "pubmed_abstracts = [abstract for abstract in pubmed_abstracts if abstract is not None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAOYlJDf9U0X"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with PubMed IDs and Abstracts\n",
        "abstract_df = pd.DataFrame({'PubMedID': pubmed_ids, 'Abstract': pubmed_abstracts})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLgTuw1d9U0X"
      },
      "outputs": [],
      "source": [
        "medk=line_df = pd.DataFrame({'PubMedID': pubmed_ids, 'Abstract': pubmed_abstracts})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSxomRH99U0X"
      },
      "outputs": [],
      "source": [
        "#to create a csv file\n",
        "#filename=open(\".csv\", \"w\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwnXbwWY9U0Y"
      },
      "outputs": [],
      "source": [
        "# Save the DataFrame to a CSV file named 'abstract.csv'\n",
        "abstract_df.to_csv('/content/drive/MyDrive/BIOBERT/abstract.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEpf5D149U0Y"
      },
      "source": [
        " # Step 2:Target Document Triage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLiy2HvA9U0Y"
      },
      "outputs": [],
      "source": [
        "# Calculate abstract lengths\n",
        "abstract_df['AbstractLength'] = abstract_df['Abstract'].apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuIw17q39U0Y"
      },
      "outputs": [],
      "source": [
        "# Sort the DataFrame by abstract length in descending order\n",
        "triaged_abstract_df = abstract_df.sort_values(by='AbstractLength', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjj0AuA59U0Y"
      },
      "outputs": [],
      "source": [
        "# Save the triaged DataFrame to a CSV file named 'triaged_abstract.csv'\n",
        "triaged_abstract_df.to_csv('/content/drive/MyDrive/BIO/triaged_abstract.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcEpAMJP9U0Y",
        "outputId": "ab19cbf2-eaaa-4ae5-9da7-c04d445838ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'with open(\"triaged_abstract.csv\",\"r\") as a:\\n    csvreader = csv.reader(a)\\n    for i in a:\\n        print(i)\\n'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#to display the data in csv file\n",
        "'''with open(\"triaged_abstract.csv\",\"r\") as a:\n",
        "    csvreader = csv.reader(a)\n",
        "    for i in a:\n",
        "        print(i)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcVuLRT09U0Z"
      },
      "source": [
        "\n",
        "# Step 3: Extract gene from the abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XU33eD239U0Z"
      },
      "outputs": [],
      "source": [
        "# Replace with the actual file paths\n",
        "gene_file_path = '/content/drive/MyDrive/BIO/GENE.csv'\n",
        "abstract_file_path = '/content/drive/MyDrive/BIO/abstract.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JF2BNmm9U0Z"
      },
      "outputs": [],
      "source": [
        "# Read gene names from the gene file\n",
        "gene_df = pd.read_csv(gene_file_path)\n",
        "genes = gene_df['Gene Symbol'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nv08ItPW9U0a"
      },
      "outputs": [],
      "source": [
        "# Read abstracts from the abstract file\n",
        "abstract_df = pd.read_csv(abstract_file_path)\n",
        "pubmed_ids = abstract_df['PubMedID'].tolist()\n",
        "abstracts = abstract_df['Abstract'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1ysFtjH9U0a"
      },
      "source": [
        "# Step 4 BERT model to tokenize the GENE from the abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XFLHL5U9U0a",
        "outputId": "1a1d2c4e-4c1d-4d41-9575-9a3742265bcb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pnEgMfd9U0a"
      },
      "outputs": [],
      "source": [
        "# Tokenize and encode the abstracts\n",
        "tokenized_abstracts = tokenizer(abstracts, return_tensors='pt', truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxJY0-7J9U0a"
      },
      "outputs": [],
      "source": [
        "# Forward pass through the model\n",
        "with torch.no_grad():\n",
        "    outputs = model(**tokenized_abstracts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXNCo0tF9U0a"
      },
      "outputs": [],
      "source": [
        "# Extract the embeddings for further analysis\n",
        "embeddings = outputs.last_hidden_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_Hrqwcz9U0a"
      },
      "outputs": [],
      "source": [
        "# Assuming you want to find mentions of each gene in the abstracts\n",
        "gene_mentions = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Law1PE_R9U0a"
      },
      "outputs": [],
      "source": [
        "for i, gene in enumerate(genes):\n",
        "    # Convert gene to string\n",
        "    gene_str = str(gene)\n",
        "\n",
        "    # Tokenize and encode the gene\n",
        "    gene_tokens = tokenizer.tokenize(gene_str)\n",
        "    gene_str = \" \".join(gene_tokens)\n",
        "\n",
        "    for j, (pubmed_id, abstract) in enumerate(zip(pubmed_ids, abstracts)):\n",
        "        # Tokenize and encode the abstract\n",
        "        abstract_tokens = tokenizer.tokenize(abstract)\n",
        "        abstract_str = \" \".join(abstract_tokens)\n",
        "\n",
        "        # Find indices of gene mentions in the abstract\n",
        "        if gene_str in abstract_str:\n",
        "            gene_mentions.append({'Gene': gene_str, 'PubMedID': pubmed_id})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5SpGOQ79U0a"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with gene mentions\n",
        "gene_mentions_df = pd.DataFrame(gene_mentions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mmy-I-Vx9U0b"
      },
      "outputs": [],
      "source": [
        "# Save the DataFrame to a CSV file named 'gene_mentions.csv'\n",
        "gene_mentions_df.to_csv('gene_mentions.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igA288989U0b"
      },
      "source": [
        "# Step 5: Finetuning the Tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgY5LXUb9U0b"
      },
      "outputs": [],
      "source": [
        "Drimport pandas as pd\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv('gene_mentions.csv')  # Replace with your file path\n",
        "\n",
        "# Removing '##' and spaces from the 'Gene' column and converting to uppercase\n",
        "df['Gene'] = df['Gene'].str.replace('##', '').str.replace(' ', '').str.upper()\n",
        "\n",
        "# Grouping by 'Gene' and aggregating 'PubMedID' into a list\n",
        "grouped_df = df.groupby('Gene')['PubMedID'].apply(list).reset_index()\n",
        "\n",
        "# Print the grouped DataFrame\n",
        "print(grouped_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Lexicon Extraction**"
      ],
      "metadata": {
        "id": "RL6wHiM0k18c"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_3L7-Ij9U0b"
      },
      "source": [
        "# Step 1: Parse TTD Target Information"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load SpaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "AIx9H0Sz_1QP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2IjDWZ-3e5g",
        "outputId": "ff18b93d-ca15-4fa6-c8f7-418405b75a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIChjrsg6aME",
        "outputId": "03ddadd7-55ad-4394-93c0-a2fedb55b4ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of cancer and melanoma-related terms\n",
        "cancer_terms = [\n",
        "    \"cancer\", \"melanoma\", \"oncology\", \"tumor\", \"carcinoma\", \"neoplasm\", \"malignancy\",\n",
        "    \"chemotherapy\", \"radiation therapy\", \"immunotherapy\", \"oncologist\", \"metastasis\",\n",
        "    \"biopsy\", \"lymphoma\", \"leukemia\", \"sarcoma\", \"malignant\", \"benign\",\n",
        "    \"radiology\", \"chemo\", \"radiotherapy\", \"hormone therapy\", \"stem cell transplant\",\n",
        "    \"precision medicine\", \"clinical trial\", \"cancer research\", \"BRCA1\", \"BRCA2\",\n",
        "    \"mammogram\", \"prostate cancer\", \"breast cancer\", \"lung cancer\", \"colorectal cancer\",\n",
        "    \"skin cancer\", \"pancreatic cancer\", \"ovarian cancer\", \"thyroid cancer\",\n",
        "    \"leukemia\", \"lymph node\", \"metastatic\", \"pathology\", \"oncogenic\", \"adenocarcinoma\",\n",
        "    \"squamous cell carcinoma\", \"biopsy\", \"tumor marker\", \"palliative care\",\n",
        "    \"radiosurgery\", \"cytotoxic\", \"angiogenesis\", \"apoptosis\", \"gene therapy\",\n",
        "    \"cancer prevention\", \"cancer symptoms\", \"tumor suppressor genes\", \"oncogenes\",\n",
        "    \"metastasize\", \"carcinogenesis\", \"cancer vaccine\", \"immunotherapy\", \"targeted therapy\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "c_R_3aFZ_3tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_cancer_entities(file_path_abstract, text_column='text'):\n",
        "    # Read the CSV file\n",
        "    data = pd.read_csv(file_path_abstract)\n",
        "\n",
        "    # Initialize a list to store cancer-related entities\n",
        "    cancer_entities = []\n",
        "\n",
        "    # Iterate over each row in the DataFrame\n",
        "    for text in data[text_column]:\n",
        "        # Process the text through the NLP model\n",
        "        doc = nlp(text)\n",
        "\n",
        "        # Extract entities using NER and add to the list\n",
        "        for ent in doc.ents:\n",
        "            if any(term in ent.text.lower() for term in cancer_terms):\n",
        "                cancer_entities.append(ent.text)\n",
        "\n",
        "        # Additionally, check for predefined cancer terms in the text\n",
        "        for term in cancer_terms:\n",
        "            if term in text.lower():\n",
        "                cancer_entities.append(term)\n",
        "\n",
        "    return cancer_entities"
      ],
      "metadata": {
        "id": "gI-IFtxU_9ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "file_path_abstract = '/content/drive/MyDrive/BIO/abstract.csv'\n",
        "cancer_entities = extract_cancer_entities(file_path_abstract, text_column='Abstract')\n",
        "print(cancer_entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvYkNjjqnHJW",
        "outputId": "67d4c0f4-2d5b-4746-b440-ca2d756b887f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cancer', 'melanoma', 'tumor', 'leukemia', 'malignant', 'leukemia', 'cancer', 'melanoma', 'tumor', 'sarcoma', 'melanoma', 'tumor', 'melanoma', 'tumor', 'radiation therapy', 'melanomas', 'cancer', 'melanoma', 'tumor', 'metastasis', 'malignant', 'skin cancer', 'metastasize', 'melanoma', 'cancer', 'melanoma', 'carcinoma', 'metastatic', 'adenocarcinoma', 'cancer', 'melanoma', 'tumor', 'metastatic', 'melanoma', 'neoplasm', 'melanomas', 'cancer', 'melanoma', 'tumor', 'malignancy', 'metastatic', 'cancer', 'melanoma', 'metastasis', 'metastatic', 'cancer', 'melanoma', 'tumor', 'metastasis', 'metastatic', 'oncogenic', 'angiogenesis', 'oncogenes', 'cancer', 'melanoma', 'tumor', 'oncogenic', 'melanoma', 'tumor', 'metastasis', 'metastatic', 'melanomas', 'melanoma', 'melanoma', 'malignant', 'cancer', 'melanoma', 'oncology', 'tumor', 'metastasis', 'malignant', 'breast cancer', 'metastatic', 'melanoma', 'cancer', 'melanoma', 'tumor', 'metastasis', 'breast cancer', 'Melanoma', 'cancer', 'melanoma', 'chemo', 'metastatic', 'apoptosis', 'metastasize', 'melanoma', 'tumor', 'melanoma', 'cancer', 'melanoma', 'lymphoma', 'leukemia', 'leukemia', 'oncogenes', 'melanoma', 'cancer', 'melanoma', 'lung cancer', 'cancer', 'melanoma', 'tumor', 'gene therapy', 'metastatic melanomas', 'melanoma', 'metastatic', 'melanoma', 'melanoma', 'tumor', 'malignant', 'melanoma', 'melanoma', 'melanoma', 'tumor', 'malignant', 'apoptosis', 'melanoma', 'malignancy', 'metastatic', 'oncogenic', 'tumor', 'neoplasm', 'malignant', 'cancer', 'melanoma', 'tumor', 'malignant', 'melanoma', 'tumor', 'melanoma', 'tumor', 'oncogenic', 'Melanoma', 'melanoma', 'tumor', 'cancer', 'melanoma', 'tumor', 'malignant', 'colorectal cancer', 'cancer', 'melanoma', 'melanoma', 'tumor', 'malignant', 'radiotherapy', 'melanoma', 'malignant', 'melanoma', 'tumor', 'melanomas', 'melanoma', 'tumor', 'benign', 'chemo', 'metastatic', 'apoptosis', 'melanoma', 'tumor', 'cancer', 'melanoma', 'carcinoma', 'breast cancer', 'oncogenes', 'melanoma', 'malignancy', 'metastatic', 'apoptosis', 'cancer', 'melanoma', 'skin cancer', 'melanoma', 'metastatic', 'cancer', 'melanoma', 'tumor', 'carcinoma', 'melanoma', '16/16 melanoma metastases', 'melanoma', 'tumor', 'malignant', 'benign', 'metastatic', 'apoptosis', 'cancer', 'melanoma', 'tumor', 'cancer', 'melanoma', 'colorectal cancer', 'melanoma', 'melanomas', 'melanoma', 'tumor', 'cancer', 'melanoma', 'malignant', 'chemo', 'melanoma', 'tumor', 'metastatic', 'melanomas', 'melanoma', 'melanoma', 'melanoma', 'tumor', 'malignant melanomas', '4 melanoma', 'melanomas', 'melanoma', 'tumor', 'metastasis', 'malignant', 'benign', 'oncogenic', 'melanoma', 'osteosarcoma', 'cancer', 'melanoma', 'tumor', 'carcinoma', 'sarcoma', 'malignant', 'metastatic', 'carcinogenesis', 'melanoma', 'cancer', 'melanoma', 'tumor', 'metastasis', 'breast cancer', 'metastatic', 'metastasize', 'cancer', 'melanoma', 'tumor', 'metastasis', 'malignant', 'metastatic', 'melanoma', 'melanoma', 'tumor', 'melanoma', 'biopsy', 'metastatic', 'biopsy', 'melanoma', 'thin melanomas', 'melanoma', 'metastatic', 'angiogenesis', 'cancer', 'melanoma', 'tumor', 'malignant', 'melanoma', 'cancer', 'melanoma', 'tumor', 'metastasis', 'prostate cancer', 'metastatic', 'mucosal melanomas', 'melanoma', 'melanoma', 'nonmelanoma', 'melanoma', 'mucosal melanomas', 'melanoma', 'tumor', 'metastatic', 'cancer', 'melanoma', 'malignant', 'breast cancer', 'melanoma', 'cancer', 'carcinogenesis', 'melanoma', 'melanoma', 'cancer', 'melanoma', 'tumor', 'metastasis', 'metastatic', 'mucosal melanomas contain alterations', 'melanoma', 'melanoma', 'melanoma', 'tumor', 'lymphoma', '10 melanoma', 'melanoma', 'melanoma', 'tumor', 'malignant', 'benign', 'oncogenic', 'apoptosis', 'carcinomas', 'carcinomas', 'cancer', 'melanoma', 'tumor', 'carcinoma', 'metastasis', 'benign', 'breast cancer', 'lymph node', 'metastatic', 'nonmelanoma', 'melanoma', 'malignancy', 'malignant', 'melanoma', 'melanoma metastasized', 'cancer', 'melanoma', 'tumor', 'chemo', 'lung cancer', 'metastasize', 'melanoma', 'tumor', 'malignant', 'metastatic', 'melanoma', 'tumor', 'malignant', 'cancer', 'melanoma', 'malignant', 'benign', 'melanomas', 'melanoma', 'melanomas', 'melanoma', 'cancer', 'melanoma', 'tumor', 'metastasis', 'cancer', 'melanoma', 'carcinoma', 'metastasis', 'sarcoma', 'malignant', 'adenocarcinoma', 'the International Hereditary Cancer Centre', 'cancer', 'melanoma', 'malignant', 'breast cancer', 'lung cancer', 'colorectal cancer', 'melanoma', 'cancer', 'melanoma', 'tumor', 'malignant', 'colorectal cancer', 'carcinogenesis', 'cancer', 'melanoma', 'tumor', 'carcinoma', 'chemotherapy', 'metastasis', 'chemo', 'angiogenesis', 'melanoma', 'melanoma', 'carcinoma', 'malignant', 'benign', 'metastatic', 'melanoma', 'cancer', 'melanoma', 'tumor', 'carcinoma', 'malignant', 'chemo', 'skin cancer', 'apoptosis', 'melanoma', 'melanoma', 'melanoma', 'melanoma', 'metastatic', 'melanoma', 'melanoma', 'metastatic', 'Melanoma', 'melanoma', 'Metastasis', 'cancer', 'melanoma', 'metastasis', 'breast cancer', 'lung cancer', 'cancer', 'melanoma', 'skin cancer', 'carcinomas', 'cancer', 'melanoma', 'tumor', 'carcinoma', 'pancreatic cancer', 'thyroid cancer', 'melanoma', 'tumor', 'cancer', 'melanoma', 'tumor', 'malignancy', 'metastasis', 'malignant', 'metastatic', 'melanoma', 'tumor', 'metastatic', 'melanoma', 'cancer', 'melanoma', 'tumor', 'metastatic', 'tumor suppressor genes', 'melanoma', 'melanoma', 'tumor', 'metastatic', 'melanoma', 'American Joint Committee on Cancer', 'cancer', 'melanoma', 'tumor', 'malignant', 'metastatic', 'cancer', 'melanoma', 'tumor', 'skin cancer', 'cancer', 'melanoma', 'malignant', 'cancer', 'melanoma', 'tumor', 'lymph node', 'Melanoma', 'melanoma', 'cancer', 'melanoma', 'tumor', 'metastasis', 'melanoma', 'malignant', 'Melanoma', 'melanoma', 'tumor', 'metastasis', 'lymph node', 'melanoma', 'tumor', 'cancer', 'melanoma', 'melanoma', 'Melanoma', 'melanoma', 'tumor', 'melanoma', 'tumor', 'melanoma', 'tumor', 'melanomas', 'mucosal melanomas', '1 melanoma', 'mucosal melanomas', 'melanoma', 'tumor', 'metastatic', 'nonfamilial melanomas', 'melanomas', 'cancer', 'melanoma', 'tumor', 'metastasis', 'malignant', 'skin cancer', 'metastatic', 'apoptosis', 'cancer', 'melanoma', 'tumor', 'breast cancer', 'melanoma', 'metastasis', 'melanoma', 'metastatic', 'apoptosis', 'Cancer Res 2006;66:2946-52', 'melanomas', 'cancer', 'melanoma', 'tumor', 'melanoma', 'lymph node', 'melanoma', 'tumor', 'malignant', 'benign', 'melanoma', 'tumor', 'metastatic', 'targeted therapy', 'cancer', 'melanoma', 'tumor', 'metastasis', 'malignant', 'cancer', 'melanoma', 'malignant', 'melanoma', 'tumor', 'carcinoma', 'metastasis', 'melanomas', 'melanomas', 'melanoma', 'cancer', 'melanoma', 'melanoma', 'cancer', 'melanoma', 'benign', 'metastatic', 'melanoma', 'melanoma', 'tumor', 'apoptosis', 'melanoma', 'tumor', 'immunotherapy', 'immunotherapy', 'melanoma', 'melanoma', 'tumor', 'angiogenesis', 'cancer', 'melanoma', 'oncogenes', 'melanomas', 'melanoma', 'tumor', 'malignant', 'chemo', 'apoptosis', 'cancer', 'melanoma', 'metastatic', 'apoptosis', 'melanoma', 'metastasis', 'Melanomas', 'melanoma', 'tumor', 'chemotherapy', 'chemo', 'oncogenic', 'malignant melanomas', 'cancer', 'melanoma', 'tumor', 'malignant', 'skin cancer', 'melanoma', 'cancer', 'melanoma', 'tumor', 'metastasis', 'cancer', 'melanoma', 'tumor', 'metastatic', 'melanoma', 'sarcoma', 'cancer', 'melanoma', 'metastatic', 'cancer', 'melanoma', 'malignancy', 'malignant', 'benign', 'melanoma', 'malignant', 'nondesmoplastic melanomas', 'melanoma', 'tumor', 'carcinoma', 'metastatic', 'cancer', 'melanoma', 'tumor', 'carcinoma', 'metastasis', 'breast cancer', 'lymph node', 'metastatic', 'Melanoma', 'melanoma', 'tumor', 'metastatic', 'mucosal melanomas', 'mucosal melanomas', 'melanoma', 'tumor', 'metastatic', 'melanoma', 'primary melanomas', 'primary melanomas', 'melanoma', 'tumor', 'metastasis', 'metastatic', 'cancer', 'melanoma', 'malignant', 'metastatic', 'melanoma', 'cancer', 'melanoma', 'tumor', 'Malignant Melanoma', 'melanoma', 'malignant', 'Melanomas', 'melanoma', 'apoptosis', 'melanoma', 'tumor', 'melanoma', 'melanoma', 'tumor', 'metastatic', 'apoptosis', 'melanoma', 'cancer', 'melanoma', 'cancer', 'melanoma', 'skin cancer', 'melanomas', 'melanoma', 'melanoma', 'cancer', 'melanoma', 'chemotherapy', 'malignant', 'chemo', 'skin cancer', 'metastatic', 'apoptosis', 'melanoma', 'tumor', 'malignant', 'tumor suppressor genes', 'oncogenes', 'melanoma', 'tumor', 'malignant', 'apoptosis', 'cancer', 'melanoma', 'breast cancer', 'melanoma', 'tumor', 'malignant', 'melanoma', 'tumor', 'metastatic', 'cancer', 'melanoma', 'leukemia', 'leukemia', 'cancer', 'melanoma', 'tumor', 'malignant', 'skin cancer', 'angiogenesis', 'melanoma', 'tumor', 'immunotherapy', 'metastatic', 'oncogenic', 'immunotherapy', 'melanoma', 'cancer', 'melanoma', 'tumor', 'metastasis', 'melanoma', 'malignant', 'benign', 'metastatic', 'melanoma', 'metastasis', 'metastatic', 'melanomas', 'cancer', 'melanoma', 'tumor', 'malignancy', 'metastatic', 'oncogenes', 'melanoma', 'neoplasm', 'metastasis', 'metastatic', 'melanomas', 'cancer', 'melanoma', 'malignant', 'benign', 'skin cancer', 'cancer', 'melanoma', 'Melanoma', 'melanoma', 'cancer', 'melanoma', 'tumor', 'metastasis', 'metastatic', 'oncogenic', 'carcinogenesis', 'cancer', 'carcinoma', 'skin cancer', 'melanoma', 'cancer', 'melanoma', 'carcinoma', 'metastasis', 'chemo', 'breast cancer', 'metastatic', 'Melanoma', 'Melanoma', 'Melanoma', 'melanoma', 'immunotherapy', 'metastasis', 'benign', 'lymph node', 'cytotoxic', 'immunotherapy', 'melanomas', 'cancer', 'melanoma', 'tumor', 'carcinoma', 'benign', 'ovarian cancer', 'cancer', 'melanoma', 'tumor', 'tumor suppressor genes', 'cancer', 'melanoma', 'tumor', 'metastatic', 'tumor suppressor genes', 'thin melanomas', 'melanoma', 'cancer', 'melanoma', 'malignant', 'skin cancer', 'ovarian cancer', 'cancer', 'melanoma', 'cancer', 'melanoma', 'tumor', 'metastasis', 'prostate cancer', 'metastatic', 'cancer', 'melanoma', 'malignant', 'melanoma', 'tumor', 'malignant', 'melanoma', 'tumor', 'Melanoma', 'melanoma', 'metastasis', 'benign', 'lymph node', 'metastatic', 'metastasize', 'cancer', 'melanoma', 'tumor', 'lung cancer', 'Melanoma', 'cancer', 'melanoma', 'tumor', 'apoptosis', 'melanoma', 'melanoma', 'tumor', 'cancer', 'melanoma', 'tumor', 'immunotherapy', 'immunotherapy', 'cancer', 'melanoma', 'tumor', 'malignant', 'oncogenic', 'melanoma', 'metastasis', 'metastatic', 'cancer', 'melanoma', 'tumor', 'apoptosis', 'tumor suppressor genes', 'oncogenes', 'melanoma', 'tumor', 'carcinoma', 'metastasis', 'metastatic', 'cancer', 'melanoma', 'tumor', 'metastatic', 'melanoma', 'precision medicine', 'melanoma', 'tumor', 'leukemia', 'leukemia', 'metastatic', 'melanoma', 'tumor', 'cancer', 'melanoma', 'melanoma', 'neoplasm', 'cancer', 'melanoma', 'tumor', 'metastasis', 'breast cancer', 'metastatic', 'cancer', 'melanoma', 'tumor', 'malignant', 'oncogenic', 'Melanoma', 'cancer', 'melanoma', 'chemotherapy', 'chemo', 'skin cancer', 'metastatic', 'apoptosis', 'melanoma', 'tumor', 'chemotherapy', 'chemo', 'metastatic', 'melanoma', 'metastasis', 'metastatic', 'cancer', 'tumor', 'immunotherapy', 'immunotherapy', 'melanoma', 'metastatic', 'cytotoxic', 'oncogenes', 'melanoma', 'melanoma', 'melanoma', 'cancer', 'melanoma', 'malignant', 'breast cancer', 'cancer', 'melanoma', 'tumor', 'thyroid cancer', 'cancer', 'melanoma', 'cancer', 'melanoma', 'tumor', 'metastasis', 'malignant', 'metastatic', 'melanoma', 'metastasis', 'cancer', 'melanoma', 'tumor', 'melanoma', 'tumor', 'benign', 'metastatic', 'apoptosis', 'cancer', 'melanoma', 'tumor', 'metastasis', 'clinical trial', 'angiogenesis', 'cancer', 'melanoma', 'tumor', 'malignant', 'melanoma', 'metastatic', 'oncogenic', 'oncogenes', 'tumor', 'cytotoxic', 'melanoma', 'cancer', 'melanoma', 'tumor', 'prostate cancer', 'thyroid carcinoma', 'cancer', 'melanoma', 'carcinoma', 'apoptosis', 'cancer', 'melanoma', 'tumor', 'skin cancer', 'melanoma', 'melanoma', 'tumor', 'melanoma', 'apoptosis', 'melanomas', 'cancer', 'melanoma', 'malignant', 'skin cancer', 'lymph node', 'oncogenic', 'melanoma', 'carcinoma', 'mouse melanomas', 'cancer', 'melanoma', 'tumor', 'angiogenesis', 'apoptosis', 'melanoma', 'melanoma', 'cancer', 'melanoma', 'cancer', 'melanoma', 'tumor', 'malignant', 'apoptosis', 'melanoma', 'cancer', 'melanoma', 'melanoma', 'metastasis', 'melanomas', 'cancer', 'melanoma', 'tumor', 'carcinoma', 'metastasis', 'breast cancer', 'metastatic', 'ovarian epithelial carcinomas', 'cancer', 'melanoma', 'tumor', 'carcinoma', 'metastasis', 'malignant', 'benign', 'breast cancer', 'lymph node', 'metastatic', 'Melanoma', 'cancer', 'melanoma', 'chemo', 'skin cancer', 'angiogenesis', 'melanoma', 'malignant', 'melanoma', 'melanoma', 'tumor', 'malignant', 'benign', 'melanoma', 'metastatic', 'melanoma', 'tumor', 'tumor suppressor genes', 'oncogenes', 'common melanomas', 'melanoma', 'sarcoma', 'cancer', 'melanoma', 'tumor', 'metastasis', 'malignant', 'metastatic', 'Metastasis', 'melanoma', 'tumor', 'metastasis', 'metastatic', 'apoptosis', 'melanoma', 'melanoma', 'melanoma', 'neoplasm', 'malignant', 'melanoma', 'nonmelanoma', 'cancer', 'melanoma', 'skin cancer', 'melanoma', 'apoptosis', 'melanoma', 'American Joint Committee on Cancer', 'cancer', 'melanoma', 'tumor', 'metastasis', 'lymph node', 'metastatic', 'The International Melanoma Genetics Consortium', 'the American Society of Clinical Oncology', 'cancer', 'melanoma', 'oncology', 'mucosal melanomas', 'mucosal melanomas', 'melanoma', 'tumor', 'melanoma', 'tumor', 'metastasis', 'metastatic', 'melanoma', 'malignancy', 'oncogenic', 'melanoma', 'angiogenesis', 'melanoma', 'tumor', 'melanoma', 'tumor', 'metastasis', 'metastatic', 'melanoma', 'skin melanomas', 'the melanomas (p<0.001', 'melanomas', 'melanoma', 'melanoma', 'metastatic', 'Melanoma', 'cancer', 'melanoma', 'tumor', 'metastasis', 'skin cancer', 'metastatic', 'melanoma', 'neoplasm', 'malignant', 'Melanoma', 'cancer', 'melanoma', 'tumor', 'skin cancer', 'apoptosis', 'melanoma', 'melanoma', 'metastasis', 'cancer', 'melanoma', 'tumor', 'lung cancer', 'metastatic', 'melanoma', 'unclassifiable melanomas', 'melanoma', 'tumor', 'apoptosis', 'melanoma', 'tumor', 'melanoma', 'pathology', 'melanoma', 'tumor', 'chemotherapy', 'chemo', 'metastatic', 'melanoma', 'tumor', 'metastatic', 'cancer', 'tumor', 'melanoma', 'metastatic', 'cancer', 'melanoma', 'tumor', 'immunotherapy', 'immunotherapy', 'melanoma', 'tumor', 'lymph node', 'melanoma', 'tumor', 'malignant', 'melanoma', 'melanoma', 'tumor', 'melanoma', 'melanoma', 'tumor', 'melanoma', 'tumor', 'leukemia', 'chemo', 'leukemia', 'oncogenic', 'apoptosis', 'cancer', 'tumor', 'angiogenesis', 'cancer', 'melanoma', 'tumor', 'melanoma', 'melanoma', 'tumor', 'cancer', 'melanoma', 'metastatic', 'melanoma', 'tumor', 'malignant', 'apoptosis', 'oncogenes', 'lymphomas', 'osteosarcoma', 'cancer', 'melanoma', 'tumor', 'carcinoma', 'lymphoma', 'leukemia', 'sarcoma', 'clinical trial', 'leukemia', 'metastatic', 'squamous cell carcinoma', 'cancer', 'melanoma', 'tumor', 'carcinoma', 'metastasis', 'melanoma', 'tumor', 'cancer', 'melanoma', 'tumor', 'chemotherapy', 'metastasis', 'malignant', 'chemo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Triggered Word Extraction**"
      ],
      "metadata": {
        "id": "xc_aj8pQ0SN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trigger_words = [\n",
        "    \"gene\", \"mutation\", \"genotype\", \"polymorphism\", \"allele\",\n",
        "    \"tumor\", \"metastasis\", \"lesion\", \"necrosis\", \"invasion\", \"progression\",\n",
        "    \"chemotherapy\", \"immunotherapy\", \"radiation\", \"inhibitor\", \"vaccine\",\n",
        "    \"pain\", \"swelling\", \"inflammation\", \"itching\", \"discoloration\",\n",
        "    \"biopsy\", \"MRI\", \"ultrasound\", \"screening\", \"endoscopy\",\n",
        "    \"survival\", \"remission\", \"recurrence\", \"mortality\", \"risk\",\n",
        "    \"cytokine\", \"receptor\", \"enzyme\", \"antibody\", \"signaling\",\n",
        "    \"immune\", \"vascular\", \"tissue\", \"cellular\", \"organ\",\n",
        "    \"prevalence\", \"incidence\", \"epidemic\", \"outbreak\", \"cohort\",\n",
        "    \"resistant\", \"responsive\", \"effective\", \"adverse\", \"toxicity\"\n",
        "]"
      ],
      "metadata": {
        "id": "Sh6zY44N9C7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_cancer_entities_and_triggers(file_path_abstract, text_column='text'):\n",
        "    data = pd.read_csv(file_path_abstract)\n",
        "    cancer_entities = []\n",
        "    found_triggers = []\n",
        "\n",
        "    for text in data[text_column]:\n",
        "        doc = nlp(text)\n",
        "\n",
        "        for ent in doc.ents:\n",
        "            cancer_entities.append(ent.text)\n",
        "\n",
        "        for trigger in trigger_words:\n",
        "            if trigger in text.lower():\n",
        "                found_triggers.append(trigger)\n",
        "\n",
        "    min_len = min(len(cancer_entities), len(found_triggers))\n",
        "    cancer_entities = cancer_entities[:min_len]\n",
        "    found_triggers = found_triggers[:min_len]\n",
        "\n",
        "    return cancer_entities, found_triggers"
      ],
      "metadata": {
        "id": "efB0PtiZ1tGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cancer_entities, triggers = extract_cancer_entities_and_triggers(file_path_abstract, text_column='Abstract')\n",
        "results_df = pd.DataFrame({'Cancer Entities': cancer_entities, 'Triggers': triggers})\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "RogPCOWd1v1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_file_path = '/content/drive/MyDrive/BIO/Triggered_words.csv'\n",
        "results_df.to_csv(output_file_path, index=False)"
      ],
      "metadata": {
        "id": "vnOmDa5r15u3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoevxcTA9U0b"
      },
      "source": [
        "##  **Feature Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read your files\n",
        "diseases_content = read_text_file('/content/drive/MyDrive/BIO/P1-01-TTD_target_download.txt')\n",
        "drugs_content = read_text_file('/content/drive/MyDrive/BIO/P1-05-Drug_disease.txt')\n",
        "relations_content = read_text_file('/content/drive/MyDrive/BIO/P1-05-Drug_disease.txt')\n"
      ],
      "metadata": {
        "id": "t04Is-XKq4lX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cancer_keywords = [\n",
        "    \"cancer\", \"melanoma\", \"oncology\", \"tumor\", \"carcinoma\", \"neoplasm\", \"malignancy\",\n",
        "    \"chemotherapy\", \"radiation therapy\", \"immunotherapy\", \"oncologist\", \"metastasis\",\n",
        "    \"biopsy\", \"lymphoma\", \"leukemia\", \"sarcoma\", \"malignant\", \"benign\",\n",
        "    \"radiology\", \"chemo\", \"radiotherapy\", \"hormone therapy\", \"stem cell transplant\",\n",
        "    \"precision medicine\", \"clinical trial\", \"cancer research\", \"BRCA1\", \"BRCA2\",\n",
        "    \"mammogram\", \"prostate cancer\", \"breast cancer\", \"lung cancer\", \"colorectal cancer\",\n",
        "    \"skin cancer\", \"pancreatic cancer\", \"ovarian cancer\", \"thyroid cancer\",\n",
        "    \"leukemia\", \"lymph node\", \"metastatic\", \"pathology\", \"oncogenic\", \"adenocarcinoma\",\n",
        "    \"squamous cell carcinoma\", \"biopsy\", \"tumor marker\", \"palliative care\",\n",
        "    \"radiosurgery\", \"cytotoxic\", \"angiogenesis\", \"apoptosis\", \"gene therapy\",\n",
        "    \"cancer prevention\", \"cancer symptoms\", \"tumor suppressor genes\", \"oncogenes\",\n",
        "    \"metastasize\", \"carcinogenesis\", \"cancer vaccine\", \"immunotherapy\", \"targeted therapy\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "6u0BuD1ayVN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_and_extract_info(file_path, keywords):\n",
        "    extracted_info = []\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            for line in file:\n",
        "                if any(keyword.lower() in line.lower() for keyword in keywords):\n",
        "                    extracted_info.append(line.strip())\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found. Please check the file path.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "    return extracted_info\n",
        "\n",
        "# Usage\n",
        "file_path = '/content/drive/MyDrive/BIO/P1-01-TTD_target_download.txt'  # Replace with your file path\n",
        "keywords = cancer_keywords\n",
        "information = read_and_extract_info(file_path, keywords)\n",
        "\n",
        "# Convert the extracted information to a dictionary with the first element as the key\n",
        "info_dict = {}\n",
        "for info in information:\n",
        "    elements = info.split('\\t')\n",
        "    key = elements[0]\n",
        "    if key not in info_dict:\n",
        "        info_dict[key] = set()  # Using a set to remove duplicates\n",
        "    info_dict[key].add(tuple(elements[1:]))\n",
        "\n",
        "# Printing the grouped information without duplicates\n",
        "'''for key, values in info_dict.items():\n",
        "    print(f\"{key}: {list(values)}\")'''\n",
        "\n",
        "\n",
        "# Provide the file path for the CSV output\n",
        "output_file = '/content/drive/MyDrive/BIO/target.csv'\n",
        "\n",
        "# Writing the extracted information to a CSV file\n",
        "with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "    csv_writer = csv.writer(csvfile)\n",
        "    csv_writer.writerow(['TargetID', 'Path', 'Type'])  # Write header row\n",
        "\n",
        "    for key, values in info_dict.items():\n",
        "        for value in values:\n",
        "            csv_writer.writerow([key] + list(value))\n",
        "\n",
        "print(f\"Data has been successfully saved to {output_file}\")"
      ],
      "metadata": {
        "id": "8k-NbjH9yXBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_and_extract_info(file_path, keywords):\n",
        "    extracted_info = []\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            for line in file:\n",
        "                if any(keyword.lower() in line.lower() for keyword in keywords):\n",
        "                    extracted_info.append(line.strip())\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found. Please check the file path.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "    return extracted_info\n",
        "\n",
        "# Usage\n",
        "file_path ='/content/drive/MyDrive/BIO/P1-02-TTD_drug_download.txt'  # Replace with your file path\n",
        "keywords = cancer_keywords\n",
        "information = read_and_extract_info(file_path, keywords)\n",
        "\n",
        "# Convert the extracted information to a dictionary with the first element as the key\n",
        "info_dict = {}\n",
        "for info in information:\n",
        "    elements = info.split('\\t')\n",
        "    key = elements[0]\n",
        "    if key not in info_dict:\n",
        "        info_dict[key] = set()  # Using a set to remove duplicates\n",
        "    info_dict[key].add(tuple(elements[1:]))\n",
        "\n",
        "# Remove specific value ('DRUGCLAS', 'Clinical Trial Drug(s)')\n",
        "unwanted_value = ('DRUGCLAS', 'Clinical Trial Drug(s)')\n",
        "for key, values in info_dict.items():\n",
        "    if unwanted_value in values:\n",
        "        values.remove(unwanted_value)\n",
        "\n",
        "# Printing the grouped information without empty lists\n",
        "filtered_info_dict = {key: values for key, values in info_dict.items() if values}\n",
        "\n",
        "'''for key, values in filtered_info_dict.items():\n",
        "    print(f\"{key}: {list(values)}\")'''\n",
        "\n",
        "# Provide the file path for the CSV output\n",
        "output_file = '/content/drive/MyDrive/BIO/drug.csv'\n",
        "\n",
        "# Writing the extracted information to a CSV file\n",
        "with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "    csv_writer = csv.writer(csvfile)\n",
        "    csv_writer.writerow(['DrugID', 'Comp/Type','Usedby'])  # Write header row\n",
        "\n",
        "    for key, values in info_dict.items():\n",
        "        for value in values:\n",
        "            csv_writer.writerow([key] + list(value))\n",
        "\n",
        "print(f\"Data has been successfully saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OvlI8qlyt3g",
        "outputId": "9b002c8a-1cb4-41a8-f697-93646375a1a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined information saved to /content/drive/MyDrive/BIO/combined_info.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Relation Extraction**"
      ],
      "metadata": {
        "id": "bA424aCIQUSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def read_and_extract_info(file_path, keywords):\n",
        "    extracted_info = {}\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            for line in file:\n",
        "                if any(keyword.lower() in line.lower() for keyword in keywords):\n",
        "                    elements = line.strip().split('\\t')\n",
        "                    if elements[0] == 'TTDDRUID' or elements[0] == 'DRUGNAME':\n",
        "                        key = elements[0]\n",
        "                        value = elements[1]\n",
        "                        if key in extracted_info:\n",
        "                            extracted_info[key].append(value)\n",
        "                        else:\n",
        "                            extracted_info[key] = [value]\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found. Please check the file path.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "    return extracted_info\n",
        "\n",
        "# Simulating file read by providing the sample_input as a string\n",
        "file_path = '/content/drive/MyDrive/BIO/P1-05-Drug_disease.txt'  # This is not the actual file path, but an example\n",
        "keywords = ['TTDDRUID', 'DRUGNAME']  # Define the keywords of interest\n",
        "information = read_and_extract_info(file_path, keywords)\n",
        "\n",
        "# Convert dictionary to DataFrame\n",
        "df = pd.DataFrame(information)\n",
        "\n",
        "# Save DataFrame to CSV file\n",
        "csv_file_path = '/content/drive/MyDrive/BIO/ID_DRUG.csv'  # Path to save CSV file\n",
        "df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "print(f\"CSV file saved to: {csv_file_path}\")"
      ],
      "metadata": {
        "id": "3RfzUe0qQoDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# File paths\n",
        "drug_path = '/content/drive/MyDrive/BIO/drug.csv'\n",
        "target_path = '/content/drive/MyDrive/BIO/target.csv'\n",
        "mapping_path = '/content/drive/MyDrive/BIO/P1-07-Drug-TargetMapping.xlsx'\n",
        "\n",
        "# Load data into dataframes\n",
        "drug_data = pd.read_csv(drug_path)\n",
        "target_data = pd.read_csv(target_path, error_bad_lines=False)\n",
        "mapping_data = pd.read_excel(mapping_path)\n",
        "\n",
        "# Extract 'TargetID' and 'DrugID' from the mapping data\n",
        "target_drug_mapping = {}\n",
        "for index, row in mapping_data.iterrows():\n",
        "    target_id = row['TargetID']\n",
        "    drug_id = row['DrugID']\n",
        "    target_drug_mapping[drug_id] = target_id\n",
        "\n",
        "# Renaming keys in the dictionary\n",
        "renamed_target_drug_mapping = {\n",
        "    'DRUGID': list(target_drug_mapping.keys()),\n",
        "    'TARGETID': list(target_drug_mapping.values())\n",
        "}\n",
        "\n",
        "# Creating a DataFrame from the renamed_target_drug_mapping dictionary\n",
        "df = pd.DataFrame(renamed_target_drug_mapping)\n",
        "output_csv_path = '/content/drive/MyDrive/BIO/TARGET_DRUG.csv'\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(f\"Data has been saved to {output_csv_path}\")"
      ],
      "metadata": {
        "id": "7frF4fmhQZsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Repurposed Drug Prioritization**\n",
        "\n"
      ],
      "metadata": {
        "id": "PEGKn-VD1-og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV files containing the extracted information\n",
        "csv_file_path_1 = '/content/drive/MyDrive/BIO/TARGET_DRUG.csv'\n",
        "csv_file_path_2 = '/content/drive/MyDrive/BIO/ID_DRUG.csv'\n",
        "\n",
        "# Read CSV files into DataFrames\n",
        "df1 = pd.read_csv(csv_file_path_1)\n",
        "df2 = pd.read_csv(csv_file_path_2)\n",
        "\n",
        "# Merge DataFrames on 'TTDDRUID'/'DRUGID'\n",
        "merged_df = pd.merge(df1, df2, left_on='DRUGID', right_on='TTDDRUID', how='inner')\n",
        "\n",
        "# Select specific columns 'DRUGID', 'TARGETID', 'DRUGNAME' from the merged DataFrame\n",
        "selected_columns = ['DRUGID', 'TARGETID', 'DRUGNAME']\n",
        "merged_selected_columns = merged_df[selected_columns]\n",
        "\n",
        "# Display the selected columns from the merged DataFrame\n",
        "print(merged_selected_columns.head())\n",
        "\n",
        "# Display or save the selected columns to a new CSV file\n",
        "merged_csv_file_path = '/content/drive/MyDrive/BIO/DRUG_ID_TARGET.csv'  # Path to save the selected columns CSV file\n",
        "merged_selected_columns.to_csv(merged_csv_file_path, index=False)\n",
        "\n",
        "print(f\"Selected columns saved to: {merged_csv_file_path}\")"
      ],
      "metadata": {
        "id": "0f4mS9huTK2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def read_and_extract_info(file_path):\n",
        "    target_ids = []\n",
        "    gene_names = []\n",
        "    current_target_id = None\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            for line in file:\n",
        "                elements = line.strip().split('\\t')\n",
        "                if len(elements) > 2:\n",
        "                    if elements[1] == 'TARGETID':\n",
        "                        current_target_id = elements[2]  # Update the current TARGETID\n",
        "                    elif elements[1] == 'GENENAME' and current_target_id:\n",
        "                        target_ids.append(current_target_id)\n",
        "                        gene_names.append(elements[2])\n",
        "                        current_target_id = None  # Reset current TARGETID for the next record\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found. Please check the file path.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "    return target_ids, gene_names\n",
        "\n",
        "# Replace with the actual file path\n",
        "file_path = '/content/drive/MyDrive/BIO/P1-01-TTD_target_download.txt'\n",
        "target_ids, gene_names = read_and_extract_info(file_path)\n",
        "\n",
        "# Convert lists to DataFrame\n",
        "df = pd.DataFrame({'TARGETID': target_ids, 'GENENAME': gene_names})\n",
        "\n",
        "# Define the CSV file path (change this to your desired file path and name)\n",
        "csv_file_path = '/content/drive/MyDrive/BIO/ID_GENE.csv'\n",
        "\n",
        "# Save to CSV\n",
        "# Change mode to 'w' for writing a new file or 'a' for appending to an existing file\n",
        "df.to_csv(csv_file_path, mode='a', index=False, header=not pd.read_csv(csv_file_path).empty)\n",
        "\n",
        "print(f\"Data added to {csv_file_path}\")\n"
      ],
      "metadata": {
        "id": "3cdnNPxa6FjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Drug Vector Space Model**"
      ],
      "metadata": {
        "id": "fC-xmCHQ1-7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load drug-target association data from CSV\n",
        "csv_file_path = '/content/drive/MyDrive/DRUG_ID_TARGET.csv'\n",
        "drug_target_df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Assuming 'DRUGNAME' column contains the drug names or identifiers\n",
        "corpus = drug_target_df['DRUGNAME'].tolist()\n",
        "\n",
        "# Vectorize the corpus using TF-IDF (Term Frequency-Inverse Document Frequency)\n",
        "vectorizer = TfidfVectorizer()\n",
        "drug_vectors = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Calculate cosine similarity between drug vectors\n",
        "similarity_matrix = cosine_similarity(drug_vectors, drug_vectors)\n",
        "\n",
        "# Plot the similarity matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(similarity_matrix, cmap='viridis', annot=False)\n",
        "plt.title('Drug Vector Similarity Matrix')\n",
        "plt.xlabel('Drug Index')\n",
        "plt.ylabel('Drug Index')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QLJK7ZTl2TJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Drug Target Similarity Ranking**"
      ],
      "metadata": {
        "id": "pwHTeaHuME7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from nltk.metrics import jaccard_distance, masi_distance, edit_distance\n",
        "\n",
        "# Load drug-target association data from CSV\n",
        "csv_file_path = '/content/drive/MyDrive/BIO/DRUG_ID_TARGET.csv'\n",
        "drug_target_df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Assuming 'DRUGNAME' column contains the drug names or identifiers as strings\n",
        "corpus = drug_target_df['DRUGNAME'].tolist()\n",
        "\n",
        "# Vectorize the corpus using TF-IDF (Term Frequency-Inverse Document Frequency)\n",
        "vectorizer = TfidfVectorizer(binary=True)\n",
        "drug_vectors = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Calculate Jaccard index for drug similarity\n",
        "jaccard_similarity_matrix = np.zeros((len(corpus), len(corpus)))\n",
        "for i in range(len(corpus)):\n",
        "    for j in range(len(corpus)):\n",
        "        jaccard_similarity_matrix[i, j] = 1 - jaccard_distance(set(corpus[i]), set(corpus[j]))\n",
        "\n",
        "# Calculate Masi distance for drug similarity (a modification of Jaccard for partial agreement)\n",
        "masi_similarity_matrix = np.zeros((len(corpus), len(corpus)))\n",
        "for i in range(len(corpus)):\n",
        "    for j in range(len(corpus)):\n",
        "        masi_similarity_matrix[i, j] = 1 - masi_distance(set(corpus[i]), set(corpus[j]))\n",
        "\n",
        "# Calculate Edit distance for drug similarity\n",
        "edit_similarity_matrix = np.zeros((len(corpus), len(corpus)))\n",
        "for i in range(len(corpus)):\n",
        "    for j in range(len(corpus)):\n",
        "        edit_similarity_matrix[i, j] = 1 / (1 + edit_distance(corpus[i], corpus[j]))\n",
        "\n",
        "# Calculate Cosine similarity for drug similarity\n",
        "cosine_similarity_matrix = cosine_similarity(drug_vectors)\n",
        "\n",
        "# Calculate Pearson correlation between similarity matrices\n",
        "pearson_corr = np.corrcoef([jaccard_similarity_matrix.flatten(), masi_similarity_matrix.flatten(),\n",
        "                            edit_similarity_matrix.flatten(), cosine_similarity_matrix.flatten()])[0, 1:]\n",
        "\n",
        "# Calculate Spearman correlation between similarity matrices\n",
        "spearman_corr = spearmanr(jaccard_similarity_matrix.flatten(), cosine_similarity_matrix.flatten())[0]\n",
        "\n",
        "print(\"Jaccard Similarity Matrix:\")\n",
        "print(jaccard_similarity_matrix)\n",
        "print(\"\\nMasi Similarity Matrix:\")\n",
        "print(masi_similarity_matrix)\n",
        "print(\"\\nEdit Similarity Matrix:\")\n",
        "print(edit_similarity_matrix)\n",
        "print(\"\\nCosine Similarity Matrix:\")\n",
        "print(cosine_similarity_matrix)\n",
        "\n",
        "print(\"\\nPearson Correlation between Similarity Matrices:\")\n",
        "print(pearson_corr)\n",
        "print(\"\\nSpearman Correlation between Jaccard and Cosine Similarity Matrices:\")\n",
        "print(spearman_corr)"
      ],
      "metadata": {
        "id": "G9U0cIU0MJ20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluation Methods**"
      ],
      "metadata": {
        "id": "EMgLMPEQQuFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load combined TARGETID-DRUGID and validation set data from CSV file\n",
        "combined_data_file = '/content/drive/MyDrive/DRUG_ID_TARGET.csv'\n",
        "\n",
        "# Read combined data from CSV file\n",
        "combined_data = pd.read_csv(combined_data_file)\n",
        "\n",
        "# Group the data by 'TARGETID' and aggregate DRUGID into a list for each TARGETID\n",
        "grouped_data = combined_data.groupby('TARGETID')['DRUGID'].agg(list).reset_index()\n",
        "\n",
        "# Create a dictionary mapping TARGETIDs to corresponding DRUGID\n",
        "TARGETID_DRUGID_mapping = dict(zip(grouped_data['TARGETID'], grouped_data['DRUGID']))\n",
        "\n",
        "# Create a dictionary mapping TARGETIDs to relevant DRUGID from the validation set\n",
        "validation_set = dict(zip(combined_data['TARGETID'], combined_data['DRUGID'].str.split(',')))\n",
        "\n",
        "# Function to calculate precision at k\n",
        "def precision_at_k(relevant_items, recommended_items, k):\n",
        "    intersection = set(recommended_items[:k]) & set(relevant_items)\n",
        "    return len(intersection) / min(k, len(relevant_items)), len(intersection)  # Return count of matches as well\n",
        "\n",
        "# Function to calculate average precision\n",
        "def average_precision(relevant_items, recommended_items):\n",
        "    precisions = [\n",
        "        precision_at_k(relevant_items, recommended_items, k + 1)\n",
        "        for k in range(len(recommended_items))\n",
        "        if recommended_items[k] in relevant_items\n",
        "    ]\n",
        "    if not precisions:\n",
        "        return 0.0, 0  # Return 0 matches if no precisions calculated\n",
        "    avg_precision = sum(p[0] for p in precisions) / len(relevant_items)\n",
        "    total_matches = sum(p[1] for p in precisions)\n",
        "    return avg_precision, total_matches\n",
        "\n",
        "# Calculate Mean Average Precision (MAP) and count of matches for different percentages of potential repurposed DRUGID\n",
        "percentages = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]  # Percentage values for top repurposed DRUGID\n",
        "TARGETID_count = 10000  # Assuming you reduced TARGETIDs to the top 2000 most frequent TARGETIDs\n",
        "\n",
        "# Lists to store MAP scores and total match counts for each percentage\n",
        "map_scores = []\n",
        "match_counts = []\n",
        "\n",
        "for percentage in percentages:\n",
        "    top_percent = int(max(len(DRUGID) for DRUGID in TARGETID_DRUGID_mapping.values()) * percentage)\n",
        "    map_scores_for_percentage = []\n",
        "    match_counts_for_percentage = []\n",
        "    for TARGETID, DRUGID in list(TARGETID_DRUGID_mapping.items())[:TARGETID_count]:\n",
        "        recommended_items = DRUGID[:top_percent]\n",
        "        relevant_items = validation_set.get(TARGETID, [])\n",
        "        avg_precision, total_matches = average_precision(relevant_items, recommended_items)\n",
        "        map_scores_for_percentage.append(avg_precision)\n",
        "        match_counts_for_percentage.append(total_matches)\n",
        "    mean_map_score = sum(map_scores_for_percentage) / len(map_scores_for_percentage)\n",
        "    total_match_count = sum(match_counts_for_percentage)\n",
        "    map_scores.append(mean_map_score)\n",
        "    match_counts.append(total_match_count)\n",
        "    print(f\"MAP for top {percentage * 100}%: {mean_map_score}, Total Matches: {total_match_count}\")\n",
        "\n",
        "# Convert lists to numpy arrays if they aren't already\n",
        "percentages = np.array(percentages)\n",
        "map_scores = np.array(map_scores)\n",
        "\n",
        "\n",
        "# Plotting the MAP scores against percentages\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(percentages, map_scores, marker='o')\n",
        "plt.title('MAP Scores for Different Percentages of Repurposed Drugs')\n",
        "plt.xlabel('Percentage (%)')\n",
        "plt.ylabel('MAP Score')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GuSbTyh7QwdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Unmatched Gene**"
      ],
      "metadata": {
        "id": "UKgu_eCmnYWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pubmed = pd.read_csv(\"/content/drive/MyDrive/BIO/GENE_GROUPED.csv\")\n",
        "df_ttd = pd.read_csv(\"/content/drive/MyDrive/BIO/ID_GENE.csv\")\n",
        "# Assuming both CSV files have a column named 'Gene' containing gene names\n",
        "pubmed_genes = set(df_pubmed['Gene'].tolist())\n",
        "ttd_genes = set(df_ttd['GENENAME'].tolist())\n",
        "\n",
        "# Find unmatched genes\n",
        "unmatched_genes_pubmed = pubmed_genes - ttd_genes\n",
        "unmatched_genes_ttd = ttd_genes - pubmed_genes\n",
        "\n",
        "print(\"Unmatched genes:\")\n",
        "print(unmatched_genes_pubmed)\n",
        "print(len(unmatched_genes_pubmed))"
      ],
      "metadata": {
        "id": "7n0klIG7n17o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visualization**"
      ],
      "metadata": {
        "id": "6tMKC5QZQxOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "# Simulated function to calculate similarity score between drugs and diseases\n",
        "def calculate_similarity(drugs, diseases):\n",
        "    similarity_matrix = np.random.rand(len(drugs), len(diseases))  # Replace this with your actual similarity calculation logic\n",
        "    return similarity_matrix\n",
        "\n",
        "# Sample data\n",
        "drugs = combined_data['DRUGID'].unique()  # Get unique drugs\n",
        "diseases = combined_data['TARGETID'].unique()  # Get unique diseases\n",
        "\n",
        "# Calculate similarity matrix between drugs and diseases\n",
        "similarity_matrix = calculate_similarity(drugs, diseases)\n",
        "\n",
        "# Example output\n",
        "print(similarity_matrix)\n",
        "\n",
        "# Visualization 2: Heatmap for Drug-Disease Relationship based on RDS values\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(similarity_matrix, cmap='coolwarm', annot=True, fmt=\".2f\")\n",
        "plt.title('Drug Repurposing: Drug-Disease Relationship (RDS values)')\n",
        "plt.xlabel('Disease Index')\n",
        "plt.ylabel('Drug Index')\n",
        "plt.show()\n",
        "\n",
        "# Additional analysis and visualization steps can be added as needed"
      ],
      "metadata": {
        "id": "wR8kZwoEH_vb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}